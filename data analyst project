import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error

df = pd.read_csv('sales.csv', parse_dates=['date'])
df = df.sort_values('date')
df.set_index('date', inplace=True)

plt.figure(figsize=(10,5))
plt.plot(df['sales'], label='Sales')
plt.title('Sales Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()

decomposition = seasonal_decompose(df['sales'], model='additive', period=12) # period=12 for monthly data
decomposition.plot()
plt.suptitle('Seasonal Decomposition')
plt.show()

train = df.iloc[:-12]
test = df.iloc[-12:]

# We'll use additive trend and seasonality (change if your data is multiplicative)
model = ExponentialSmoothing(
    train['sales'],
    trend='add',
    seasonal='add',
    seasonal_periods=12
)
hw_fit = model.fit()

forecast = hw_fit.forecast(steps=len(test))
mape = mean_absolute_percentage_error(test['sales'], forecast)
rmse = np.sqrt(mean_squared_error(test['sales'], forecast))
print(f"MAPE: {mape:.2%}")
print(f"RMSE: {rmse:.2f}")

plt.figure(figsize=(10,5))
plt.plot(train.index, train['sales'], label='Train')
plt.plot(test.index, test['sales'], label='Test', marker='o')
plt.plot(test.index, forecast, label='Forecast', marker='x')
plt.title('Sales Forecast vs Actual')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()
future_forecast = hw_fit.forecast(steps=12)
plt.figure(figsize=(10,5))
plt.plot(df['sales'], label='Historical Sales')
plt.plot(pd.date_range(df.index[-1], periods=13, freq='M')[1:], future_forecast, label='Future Forecast', marker='x')
plt.title('Future Sales Forecast')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()

